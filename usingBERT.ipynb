{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c0d222e-4398-4a6c-a067-59fb1303071a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Content  cevre_category\n",
      "0     ANTALYA - Sağlık ve Sigorta Yöneticileri Dern...               1\n",
      "1    Meteoroloji Genel Müdürlüğü ( MGM, güncel hava...               1\n",
      "2     fentanil, uyuşturucu krizinin üçüncü dalgası ...               0\n",
      "3    Plastikleri hayatımızdan çıkarmanın önemi ile ...               1\n",
      "4    Devir hızla değişiyor, etrafımızdaki her şey ç...               0\n",
      "..                                                 ...             ...\n",
      "295  \\r\\n\\r\\nCumhur İttifakı Bayraklı Belediye Başk...               0\n",
      "296  \\r\\n\\r\\nBaşkan Recep Tayyip Erdoğan, \"Bugüne k...               0\n",
      "297  \\r\\n\\r\\nFethiye ve Marmaris'in körfezlerini ba...               1\n",
      "298  İstanbul Büyükşehir Belediye Başkan Adayı Mura...               1\n",
      "299  Mansur Yavaş, Bala ilçesinde Seçim Koordinasyo...               1\n",
      "\n",
      "[300 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Örnek etiketli veri kümesi (manuel olarak oluşturulmuş)\n",
    "labeled_data = pd.DataFrame({\n",
    "    'Content': [\n",
    "        \"Küresel ısınma dünya çapında ciddi etkiler yaratıyor...\",\n",
    "        \"Ekonomi bakanı yeni teşvik paketini açıkladı...\",\n",
    "        \"Deniz seviyelerinin yükselmesi kıyı şehirlerini tehdit ediyor...\",\n",
    "        \"Yeni bir güneş enerjisi santrali açıldı...\",\n",
    "        \"Yerel halk, orman yangınlarına karşı önlem alıyor...\",\n",
    "        \"Teknoloji şirketi yeni bir akıllı telefon tanıttı...\",\n",
    "        \"Plastik atıkların okyanuslara zarar verdiği tespit edildi...\",\n",
    "        \"Uluslararası anlaşmalar iklim değişikliğiyle mücadeleyi hedefliyor...\",\n",
    "        \"Spor müsabakalarında büyük heyecan yaşandı...\",\n",
    "        \"Yeni tarım teknikleri sürdürülebilirlik sağlıyor...\",\n",
    "        \"Hava kirliliği insan sağlığını olumsuz etkiliyor...\",\n",
    "        \"Fosil yakıtların kullanımının azaltılması gerektiği belirtiliyor...\",\n",
    "        \"Ormanlar karbon emilimi için kritik öneme sahip...\",\n",
    "        \"Yeni yürüyüş parkuru doğaseverlerin ilgisini çekiyor...\",\n",
    "        \"İklim değişikliği nedeniyle kuraklık artıyor...\",\n",
    "        \"Elektrikli araçların yaygınlaşması karbon ayak izini azaltıyor...\",\n",
    "        \"Yerel yönetimler geri dönüşüm programlarını artırıyor...\",\n",
    "        \"Yapay zeka alanında büyük ilerlemeler kaydedildi...\",\n",
    "        \"Sanat galerisi yeni sergi açtı...\",\n",
    "        \"Geleceğin enerji kaynakları yenilenebilir enerji olacak...\",\n",
    "        \"Şehirde toplu taşıma sistemleri genişletiliyor...\",\n",
    "        \"Küresel biyolojik çeşitlilik tehlikede...\",\n",
    "        \"Çevre dostu binalar enerji tasarrufu sağlıyor...\",\n",
    "        \"Uzay araştırmalarında yeni keşifler yapıldı...\",\n",
    "        \"Geri dönüşüm fabrikası yeni tesis açtı...\",\n",
    "        \"Ulusal parklar biyolojik çeşitliliği korumada önemli rol oynuyor...\",\n",
    "        \"Orman yangınları doğal yaşamı tehdit ediyor...\",\n",
    "        \"Temiz enerji teknolojileri hızla gelişiyor...\",\n",
    "        \"Gıda israfını azaltma kampanyaları başlatıldı...\",\n",
    "        \"Su kaynaklarının korunması için yeni düzenlemeler yapıldı...\"\n",
    "    ],\n",
    "    'cevre_category': [\n",
    "        1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
    "        1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
    "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1\n",
    "    ]\n",
    "})\n",
    "labeled_data2 = pd.read_csv(\"çevehaberlerikatogorizeedilmis.csv\")\n",
    "labeled_data2 = labeled_data2[['Content', 'cevre_category']]\n",
    "labeled_data = pd.concat([labeled_data, labeled_data2], ignore_index=True)\n",
    "print(labeled_data2)\n",
    "# Eğitim ve doğrulama setlerine bölme\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    labeled_data['Content'], labeled_data['cevre_category'], test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "095260e2-f392-4e8a-bbed-223964b4a325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='99' max='99' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [99/99 33:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.685631</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.385027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.662624</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.385027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.489715</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.758021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=99, training_loss=0.6564562248461174, metrics={'train_runtime': 2010.76, 'train_samples_per_second': 0.394, 'train_steps_per_second': 0.049, 'total_flos': 208383955845120.0, 'train_loss': 0.6564562248461174, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer,BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "model_name = \"bert-base-multilingual-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2).to('cpu')\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "# Veri seti sınıfı\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer(text, truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "        item = {key: val.squeeze() for key, val in inputs.items()}\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "# Eğitim ve doğrulama veri setleri\n",
    "train_dataset = NewsDataset(train_texts.tolist(), train_labels.tolist(), tokenizer)\n",
    "val_dataset = NewsDataset(val_texts.tolist(), val_labels.tolist(), tokenizer)\n",
    "\n",
    "# Eğitim argümanları\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    no_cuda=True  # CUDA kullanmamak için ekleyin\n",
    ")\n",
    "\n",
    "# Trainer oluşturma\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    compute_metrics=compute_metrics,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "# Modeli eğitme\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e01dc4-95a3-42d4-9dc6-029252058725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.6536951661109924,\n",
       " 'test_runtime': 44.7765,\n",
       " 'test_samples_per_second': 1.474,\n",
       " 'test_steps_per_second': 0.201}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_output = trainer.predict(val_dataset)\n",
    "preds_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95a3e9e1-cd29-4d40-b433-699d0b2052bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tahmin Sınıfı: 1\n",
      "Tahmin Yüzdesi: 0.8770196437835693\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input_text = \"çevre iklim yağış sel deprem\"\n",
    "\n",
    "\n",
    "\n",
    "inputs = tokenizer(input_text, truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "# Dönüştürülmüş veriyi modele yükleyin\n",
    "inputs = {key: val.to(trainer.args.device) for key, val in inputs.items()}\n",
    "\n",
    "# Modelin tahmin yapmasını sağlayın\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Tahminleri alın\n",
    "predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "# Tahmin sonuçlarını yazdırın\n",
    "print(\"Tahmin Sınıfı:\", predicted_class)\n",
    "\n",
    "probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "predicted_probability = probabilities[0][predicted_class].item()\n",
    "\n",
    "print(\"Tahmin Yüzdesi:\", predicted_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2761940-0ee5-4729-9360-2f7b93466c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 392/392 [20:33<00:00,  3.15s/it]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm  \n",
    "\n",
    "data = pd.read_csv(\"birlesik_son02_df.csv\")  \n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\W', ' ', text)  \n",
    "    text = text.lower()  \n",
    "    return text\n",
    "\n",
    "data['cleaned_text'] = data['content'].apply(clean_text)\n",
    "\n",
    "unlabeled_dataset = NewsDataset(data['cleaned_text'], tokenizer=tokenizer)\n",
    "# Dataset ve DataLoader\n",
    "dataloader = DataLoader(unlabeled_dataset, batch_size=32, num_workers=4)  # Batch size ve num_workers değerlerini ayarlayın\n",
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "\n",
    "pseudo_labels = []\n",
    "\n",
    "# Model tahminleri\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        inputs = {key: val.to(device) for key, val in batch.items()}\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        predicted_probabilities = probabilities.max(dim=-1).values\n",
    "        predicted_classes = logits.argmax(dim=-1)\n",
    "        \n",
    "        for prob, pred_class in zip(predicted_probabilities, predicted_classes):\n",
    "            if prob.item() > 0.70:  # 60% üzerinde güvenle tahmin\n",
    "                pseudo_labels.append(pred_class.item())\n",
    "            else:\n",
    "                pseudo_labels.append(-1)  # Belirsiz tahminler için -1\n",
    "\n",
    "data['pseudo_label'] = pseudo_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b80c0b8-54ab-4bbe-9f80-48ee7f9e3fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>pseudo_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gazeteduvar</td>\n",
       "      <td>DUVAR - Türkiye Futbol Federasyonu, Galatasar...</td>\n",
       "      <td>11-3-2023</td>\n",
       "      <td>duvar   türkiye futbol federasyonu  galatasar...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sozcu</td>\n",
       "      <td>Şarkıcı ve sosyal medya fenomeni Banu Parlak,...</td>\n",
       "      <td>11-3-2023</td>\n",
       "      <td>şarkıcı ve sosyal medya fenomeni banu parlak ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gazeteduvar</td>\n",
       "      <td>DUVAR - Artan kira fiyatları, metropollerin y...</td>\n",
       "      <td>11-3-2023</td>\n",
       "      <td>duvar   artan kira fiyatları  metropollerin y...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aa</td>\n",
       "      <td>İstanbulda pazar günü düzenlenecek 45. İstanbu...</td>\n",
       "      <td>11-3-2023</td>\n",
       "      <td>i̇stanbulda pazar günü düzenlenecek 45  i̇stan...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sozcu</td>\n",
       "      <td>Sakaryanın Hendek ilçesindeki bir inşaatta er...</td>\n",
       "      <td>11-3-2023</td>\n",
       "      <td>sakaryanın hendek ilçesindeki bir inşaatta er...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12519</th>\n",
       "      <td>haberturk</td>\n",
       "      <td>Bolu'da, kontrolden çıkarak şarampole devrilen...</td>\n",
       "      <td>05-27-2024</td>\n",
       "      <td>bolu da  kontrolden çıkarak şarampole devrilen...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12525</th>\n",
       "      <td>haberturk</td>\n",
       "      <td>Olay, Konya'da meydana geldi.Kız arkadaşıyla m...</td>\n",
       "      <td>05-27-2024</td>\n",
       "      <td>olay  konya da meydana geldi kız arkadaşıyla m...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12526</th>\n",
       "      <td>haberturk</td>\n",
       "      <td>Zafer Partisi Genel Başkanı Ümit Özdağ, Sandık...</td>\n",
       "      <td>05-27-2024</td>\n",
       "      <td>zafer partisi genel başkanı ümit özdağ  sandık...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12529</th>\n",
       "      <td>haberturk</td>\n",
       "      <td>Edinilen bilgiye göre, Ankara İl Jandarma Komu...</td>\n",
       "      <td>05-27-2024</td>\n",
       "      <td>edinilen bilgiye göre  ankara i̇l jandarma kom...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12535</th>\n",
       "      <td>haberturk</td>\n",
       "      <td>Cikcilli Mahallesi'nde bir inşaatın beşinci ka...</td>\n",
       "      <td>05-27-2024</td>\n",
       "      <td>cikcilli mahallesi nde bir inşaatın beşinci ka...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3429 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            source  ... pseudo_label\n",
       "3      gazeteduvar  ...           -1\n",
       "5            sozcu  ...           -1\n",
       "6      gazeteduvar  ...           -1\n",
       "9               aa  ...           -1\n",
       "12           sozcu  ...           -1\n",
       "...            ...  ...          ...\n",
       "12519    haberturk  ...           -1\n",
       "12525    haberturk  ...           -1\n",
       "12526    haberturk  ...           -1\n",
       "12529    haberturk  ...           -1\n",
       "12535    haberturk  ...           -1\n",
       "\n",
       "[3429 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['pseudo_label']==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c46beae8-30b2-4a4b-8848-e0dd406f7934",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"trainedilmis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7e19f-6704-46d4-997f-6c625cce5692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Etiketlenmemiş veri seti\n",
    "data = pd.read_csv(\"birlesik_data.csv\")  # lemmatize edilmemiş bütün veri olsun\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\W', ' ', text)  \n",
    "    text = text.lower()  \n",
    "    return text\n",
    "\n",
    "data['cleaned_text'] = data['content'].apply(clean_text)\n",
    "unlabeled_dataset = NewsDataset(data['cleaned_text'], tokenizer=tokenizer)\n",
    "\n",
    "# Pseudo-labeling: Etiketlenmemiş veri üzerinde tahmin yapma\n",
    "pseudo_labels = []\n",
    "for i in range(len(unlabeled_dataset)):\n",
    "    inputs = unlabeled_dataset[i]\n",
    "    inputs = {key: val.unsqueeze(0).to(trainer.args.device) for key, val in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    predicted_probability = probabilities[0][predicted_class].item()\n",
    "    if 60 > int(predicted_probability):  \n",
    "        pseudo_labels.append(logits.argmax(dim=-1).item())\n",
    "data['pseudo_label'] = pseudo_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3044f7c-d03c-4472-9802-f7c54f1d1e46",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unlabeled_texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m pseudo_labeled_dataset \u001b[38;5;241m=\u001b[39m NewsDataset(unlabeled_dataset, pseudo_labels, tokenizer)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Etiketli veri seti ile pseudo-labeled veri setini birleştirme\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m combined_texts \u001b[38;5;241m=\u001b[39m train_texts\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;241m+\u001b[39m \u001b[43munlabeled_texts\u001b[49m\n\u001b[1;32m      6\u001b[0m combined_labels \u001b[38;5;241m=\u001b[39m train_labels\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;241m+\u001b[39m pseudo_labels\n\u001b[1;32m      7\u001b[0m combined_dataset \u001b[38;5;241m=\u001b[39m NewsDataset(combined_texts, combined_labels, tokenizer)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unlabeled_texts' is not defined"
     ]
    }
   ],
   "source": [
    "# Pseudo-label'ları etiketlenmemiş veri setine ekleme\n",
    "pseudo_labeled_dataset = NewsDataset(unlabeled_dataset, pseudo_labels, tokenizer)\n",
    "\n",
    "# Etiketli veri seti ile pseudo-labeled veri setini birleştirme\n",
    "combined_texts = train_texts.tolist() + unlabeled_texts\n",
    "combined_labels = train_labels.tolist() + pseudo_labels\n",
    "combined_dataset = NewsDataset(combined_texts, combined_labels, tokenizer)\n",
    "\n",
    "# Modeli tekrar eğitme\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=combined_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7aa89ca9-53f9-4943-8b8f-f666946b2ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3516df8f-4ef7-48fd-b03a-139b7a872db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 16\n",
    "\n",
    "unlabeled_dataloader = DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "pseudo_labels = []\n",
    "\n",
    "# EVAL MODU MANTIKLI MI?\n",
    "model.eval()\n",
    "\n",
    "#GPU varsa\n",
    "model.to(trainer.args.device)\n",
    "\n",
    "# Disable gradient computation\n",
    "with torch.no_grad():\n",
    "    for batch in unlabeled_dataloader:\n",
    "        \n",
    "        inputs = {key: val.to(trainer.args.device) for key, val in batch.items()}\n",
    "        \n",
    "   \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        \n",
    "        batch_pseudo_labels = logits.argmax(dim=-1).cpu().numpy()\n",
    "        \n",
    "\n",
    "        pseudo_labels.extend(batch_pseudo_labels)\n",
    "\n",
    "\n",
    "data['pseudo_label'] = pseudo_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15e62c3c-14ea-4eea-9956-e8acd4ab7d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>pseudo_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sozcu</td>\n",
       "      <td>i̇srail , vatandaş Yurt dış seyahat i̇srail ve...</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>i srail   vatandaş yurt dış seyahat i srail ve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>euronews</td>\n",
       "      <td>By Euronews yayın tarih 03/11/2023 - 18:22 hab...</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>by euronews yayın tarih 03 11 2023   18 22 hab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sozcu</td>\n",
       "      <td>Frans dışişleri bakanlık , i̇srailin düzenleme...</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>frans dışişleri bakanlık   i srailin düzenleme...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gazeteduvar</td>\n",
       "      <td>duvar - Türkiye futbol federasyon , Galatasara...</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>duvar   türkiye futbol federasyon   galatasara...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>euronews</td>\n",
       "      <td>By Euronews yayın tarih 03/11/2023 - 15:18 hab...</td>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>by euronews yayın tarih 03 11 2023   15 18 hab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11238</th>\n",
       "      <td>SABAH</td>\n",
       "      <td>\\r\\n\\r\\nİstanbul Fatih'te kuaförlük mesleği ya...</td>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>i̇stanbul fatih te kuaförlük mesleği yapan ab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11239</th>\n",
       "      <td>SABAH</td>\n",
       "      <td>\\r\\n\\r\\nBakırlı konuşmasına \"Bu CHP'nin adayı ...</td>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>bakırlı konuşmasına  bu chp nin adayı muhtarl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11240</th>\n",
       "      <td>SABAH</td>\n",
       "      <td>\\r\\n\\r\\nBelediye başkan adaylığı açıklandığı g...</td>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>belediye başkan adaylığı açıklandığı günden b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11241</th>\n",
       "      <td>SABAH</td>\n",
       "      <td>\\r\\n\\r\\nAK Parti Muğla Büyükşehir Belediye Baş...</td>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>ak parti muğla büyükşehir belediye başkan ada...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11242</th>\n",
       "      <td>SABAH</td>\n",
       "      <td>\\r\\n\\r\\nİmamoğlu, İBB Başkanı olmasından kısa ...</td>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>i̇mamoğlu  i̇bb başkanı olmasından kısa süre ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11243 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            source                                            content  \\\n",
       "0            sozcu  i̇srail , vatandaş Yurt dış seyahat i̇srail ve...   \n",
       "1         euronews  By Euronews yayın tarih 03/11/2023 - 18:22 hab...   \n",
       "2            sozcu  Frans dışişleri bakanlık , i̇srailin düzenleme...   \n",
       "3      gazeteduvar  duvar - Türkiye futbol federasyon , Galatasara...   \n",
       "4         euronews  By Euronews yayın tarih 03/11/2023 - 15:18 hab...   \n",
       "...            ...                                                ...   \n",
       "11238        SABAH  \\r\\n\\r\\nİstanbul Fatih'te kuaförlük mesleği ya...   \n",
       "11239        SABAH  \\r\\n\\r\\nBakırlı konuşmasına \"Bu CHP'nin adayı ...   \n",
       "11240        SABAH  \\r\\n\\r\\nBelediye başkan adaylığı açıklandığı g...   \n",
       "11241        SABAH  \\r\\n\\r\\nAK Parti Muğla Büyükşehir Belediye Baş...   \n",
       "11242        SABAH  \\r\\n\\r\\nİmamoğlu, İBB Başkanı olmasından kısa ...   \n",
       "\n",
       "             date                                       cleaned_text  \\\n",
       "0      2023-11-03  i srail   vatandaş yurt dış seyahat i srail ve...   \n",
       "1      2023-11-03  by euronews yayın tarih 03 11 2023   18 22 hab...   \n",
       "2      2023-11-03  frans dışişleri bakanlık   i srailin düzenleme...   \n",
       "3      2023-11-03  duvar   türkiye futbol federasyon   galatasara...   \n",
       "4      2023-11-03  by euronews yayın tarih 03 11 2023   15 18 hab...   \n",
       "...           ...                                                ...   \n",
       "11238  2024-04-22   i̇stanbul fatih te kuaförlük mesleği yapan ab...   \n",
       "11239  2024-04-22   bakırlı konuşmasına  bu chp nin adayı muhtarl...   \n",
       "11240  2024-04-22   belediye başkan adaylığı açıklandığı günden b...   \n",
       "11241  2024-04-22   ak parti muğla büyükşehir belediye başkan ada...   \n",
       "11242  2024-04-22   i̇mamoğlu  i̇bb başkanı olmasından kısa süre ...   \n",
       "\n",
       "       pseudo_label  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "11238             0  \n",
       "11239             0  \n",
       "11240             0  \n",
       "11241             0  \n",
       "11242             0  \n",
       "\n",
       "[11243 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['pseudo_label'] == 0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
